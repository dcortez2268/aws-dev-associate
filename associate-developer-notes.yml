AWS SECURITY TOKEN SERVICE, STS:
  provides identities assuming a role the temporary security credentials they need for access:
  sts:AssumeRole action generates temporary credentials:
  credentials are similar to access keys:
  credentials can be given subset of permissions of permissions policy of role:
  when an identity assumes a role:
    sts:AssumeRole calls are made to STS
    STS requests permissions policy from role and generates credentials based on permissions policy
    STS returns credentials
  temporary credentials contain:
    AccessKeyId, Expiration, SecretAccessKey, SessionToken

-----------------------------------------------------------------------------------------------:
S3 BUCKET KEYS (know all):
  using S3 SEE-KMS without bucket keys:
    each object uploaded via PUT method uses a unique DEK when using KMS key
    the unique DEK is stored with the object
    limits scalability
  using S3 SEE-KMS with bucket keys:
    KMS key is used to generate a time limited bucket key
    time limited bucket key:
      generates DEKs within s3, offloading the work from KMS and reducing the number of KMS api calls
    increases scalability
    cloudtrail kms event logs now show the bucket ARN instead of object ARN
    works with replication...object encryption is maintained
    not retroactive

-----------------------------------------------------------------------------------------------:
CLOUDWATCH LOGS ARCHITECTURE:
  two sides:
    ingestion side:
      public service that allows you to store, monitor, and access logging data
      natively logs AWS services logs (VPC flow logs, cloudtrail, ebs, ecs, api gateway, lambda, route53, and others)
      CWAgent allows you to log system, custom application, and on premises logging
    subscription side:
      log events:
        a specific occurrence or action that is logged by a service or application
        consist of timestamp and raw message
      log stream:
        a collection of log events that are generated by a single source, such as an EC2 instance
      log group:
        a collection of related log streams
        sets retention (by default logs are stored indefinitely), access permissions, and encryption at rest using KMS
        defines metric filter to analyze patterns within log group and creates a metric
        subscription filter allows real time delivery
      s3 export:
        logs are exported to s3 bucket via CreateExportTask api call
        takes up to 12 hours
        you can encrypt data with only sse-s3 encryption method
      subscription filter:
        allows real time and near real time delivery of log groups
        configures pattern, destination ARN, distribution, access permissions
        near realtime delivery:
          kinesis data firehose allows near realtime delivery
        real time delivery:
          aws managed lambda function natively delivers into elasticsearch in realtime delivery
          custom lambda functions can be used to export data to nearly any destination in realtime
          can deliver to a kinesis data stream in realtime

-----------------------------------------------------------------------------------------------:
S3 REQUESTOR PAYS FEATURE:
  allows requestor of data, instead of bucket owner, to pay the cost of the request:
  unathenticated access is not supported:
  doesn't work with static website hosting or bitTorrent
  bucket level setting
  requesters must add x-amz-request-payer header to confirm payment responsibility

-----------------------------------------------------------------------------------------------:
POLICY INTERPRETATION:
  follow these steps when evaluating policy:
    identify number of statements:
    identify at a high level what each statement does:
    identify overlap of any statements:
    statements with condition field take effect when that condition is true
    'NotAction' field allows all actions besides the actions listed in value, there are a lot of inverses used in policies so be on lookout for those on exam

-----------------------------------------------------------------------------------------------:
POLICY EVALUATION LOGIC:
  for same account:
    aws checks pile of policies in this order:
      explicit denys:
        if it denies, permission is denied and evaluation stops
      organization SCPS on identity's account:
        if it denies, permission is denied and evaluation stops
      resource policies:
        if it allows, permission is allowed and evaluation stops
      IAM identity/permission boundaries:
        permission boundaries allow you to limit permissions granted
        if it denies, permission is denied and evaluation stops
      role/session policies:
        session policies allow you only a subset of role permissions
        if it exists and it denies, permission is denied and evaluation stops
      identity policies:
        access is denied or allowed, or implicit deny
    
    for multi account (account a trying to access account b's resources):
      has same checks as above for account a and also needs a resource policy allowing in account b 

-----------------------------------------------------------------------------------------------:
X-RAY:
  distributed tracing application, it is designed to track sessions through an application:
  aggregrates different services data to give you a single overview of flow of data:
  services sending data into xray require iam permissions:
  tracing header:
    the first service of session generates this which is used to track a request through your distributed application
  segments:
    single block of data sent into xray
    contains host/ip, request, response, work done (times), and issues
  subsegments:
    more granular version of segments
  service graph:
    JSON document that details services and resources which make up your app
  service map:
    visual version of the service graph 
  to integrate with aws ray these services require configuration:
    ec2: xray agent
    ec2: agent in tasks
    lambda: there is an enable option
    beanstalk: agent preinstalled
    api gateway: per stage option
    sns and sqs: there is an enable option

-----------------------------------------------------------------------------------------------:
CI/CD USING AWS CODE: 5:54
  stages of ci/cd development pipeline:
    code:
      focuses on actual coding process, storage, version control
    build:
      focuses on combining src code, libraries, frameworks, and generates output
    test:
      tests code against expectations
    deploy:
      getting code out to code environments where it will run
    
    without aws:
      manually configure... github (code) -> jenkins (build+test) -> jenkins/other tooling (deploy)
      integration with aws has to be configured
    with aws:
      CodeCommit (code) -> CodeBuild (build+test) -> CodeDeploy (deploy)
      CodePipeline service orchestrates all of these services together
  
  CodePipeline:
    each pipeline has stages
    every pipeline at minimum has source stage which defines where source code is located within specific branch within specific repo
    buildspec.yml:
      collection of build commands and related configuration that CodeBuild implements to run a build
    appspec.yml|json:
      defines exactly how a deployment process proceeds that CodeDeploy implements

  CodeDeploy destinations:
    codeDeploy:
      can be deployed onto one or more ec2 instances using a deployment group
    elastic beanstalk or OpsWorks:
    cloudformation:
      can create/update stacks
    ecs or ecs (blue/green deployment model):
    service catalog or alexa skills kit:
    s3:
    